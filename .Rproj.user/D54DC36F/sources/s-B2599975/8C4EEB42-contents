library(caret)

#############################
# Data Splitting mit swiss
#############################

df=swiss
partition <- sample(seq_len(nrow(df)), size = nrow(df)*0.75)
train <- df[partition, ] # Select the training rows
test <- df[-partition, ] # Select the test rows
# mit caret
partition <- createDataPartition(df[,1], times = 1, p = 0.75,list = FALSE)
partition
train <- df[partition,] # Create the training sample
test = df[-partition,] # Create the test sample

dim(train)
dim(test)

#############################
# Lineare Regression als Machine Learning Modell mit swiss
#############################

library(caret)
df=swiss
partition <- sample(seq_len(nrow(df)), size = nrow(df)*0.75)
train <- df[partition, ] # Select the training rows
test <- df[-partition, ] # Select the test rows
model=lm(Fertility~.,data=train)
score=predict(model,newdata=test)

model
score
#############################
# Regressionsmodell auswerten mit swiss
#############################

resid=(test$Fertility-score)
MSE = mean(resid^2)
RMSE=sqrt(mean(resid^2))
MeanAE=mean(abs(resid))
MedianAE=median(abs(resid))
print(paste("Mean Square Error MSE:",MSE))
print(paste("Root Mean Square Error RMSE:",RMSE))
print(paste("Mean Absolute Error:",MeanAE))
print(paste("Median Absolute Error:",MedianAE))
#oder einfacher
postResample(test$Fertility,score)

# Einfacheres Modell
model2=lm(Fertility~Agriculture+Infant.Mortality,data=swiss)
score2=predict(model2,newdata=test)
postResample(test$Fertility,score2)

# Kommentar: einfacheres Modell performt ungefähr gleich gut.

#############################
# Training mit caret mit swiss
#############################

model.lm <- train(Fertility ~ ., data = train, method = "lm")
score=predict(model.lm,newdata=test)
postResample(test$Fertility,score)

#ein anderes Modell: z.B. blasso
model.blasso <- train(Fertility ~ ., data = train, method = "blasso")
summary(model.blasso)
score=predict(model.blasso,newdata=test)
postResample(test$Fertility,score)

#############################
# Classification mit kNN mit iris
#############################

str(iris)
head(iris)
View(iris)
df=iris
partition <- createDataPartition(df[,1], times = 1, p = 0.75, 
                                 list = FALSE)
train <- df[partition,] # Create the training sample
test = df[-partition,] # Create the test sample
tune.grid=expand.grid(k=c(1:30))
tune.grid
model=train(Species~.,method='knn',data=train,tuneGrid=tune.grid)
model
score=predict(model,newdata=test)
confusionMatrix(score,test$Species)

#############################
# Parameter-Tuning mit tuneGrid mit iris
#############################

params <- getModelInfo("knn")
params$knn$parameters
tune.grid=expand.grid(k=1:30)
model=train(Species~.,method='knn',data=train,tuneGrid=tune.grid)
print(model)

score=predict(model,newdata=test)
confusionMatrix(score,test$Species)

#Klassifizierung mit breastcancer.csv - Zielvariabel Class
breastcancer=read.csv("breastcancer.csv")
View(breastcancer)
breastcancer=breastcancer[,-1]
str(breastcancer)

View(breastcancer)
str(breastcancer)
breastcancer$Class=as.factor(breastcancer$Class)
df=na.omit(breastcancer)
partition <- createDataPartition(df[,1], times = 1, p = 0.75, 
                                 list = FALSE)
train <- df[partition,] # Create the training sample
test = df[-partition,] # Create the test sample

tune.grid=expand.grid(k=1:30)
model=train(Class~.,method='knn',data=train,tuneGrid=tune.grid)
print(model)

score=predict(model,newdata=test)
confusionMatrix(score,test$Class)


#############################
# Skalieren und Zentrieren mit swiss
#############################

#training ohne Skalierung
df=swiss
partition <- createDataPartition(df[,1], times = 1, p = 0.75, 
                                 list = FALSE)
train = df[partition,] 
test = df[-partition,] 
model.lm <- train(Fertility ~ ., data = train, method = "lm")
score=predict(model.lm,newdata=test)
postResample(test$Fertility,score)

#Skalierung
preProcValues <- preProcess(train[,-5], method=c("center","scale"))
train=predict(preProcValues,train)
test=predict(preProcValues,test)

model.lm <- train(Fertility ~ ., data = train, method = "lm")
score=predict(model.lm,newdata=test)
postResample(test$Fertility,score)
#Kommentar: die Vorhersagen sind deutlich besser geworden.

#############################
# Datentypen, Nutzlose Information entfernen Titanic-Beispiel
#############################

titanic=read.csv("titanic.csv")
str(titanic)

#Datentypen korrigieren, d.h. Kategorische Variabeln müssen Typ Factor sein
titanic$Survived=as.factor(titanic$Survived)
titanic$Pclass=factor(titanic$Pclass)
str(titanic)

#Nutzlose Variabeln entfernen
useless=c("PassengerId","Ticket","Name","Cabin")
titanic = titanic[,!(names(titanic) %in% useless)] 
str(titanic)

# ######################
# #alternativ könnten wir bei Cabin nur das Deck nehmen, d.h. den ersten Buchstaben
# titanic=read.csv("titanic.csv")
# titanic$Cabin=as.character(titanic$Cabin)
# titanic$Cabin[titanic$Cabin == ""] <- "U"
# titanic$Cabin = sapply(titanic$Cabin, function(char) as.factor(strsplit(char,"")[[1]][1]))
# table(titanic$Cabin)
# 
# useless=c("PassengerId","Ticket","Name")
# titanic = titanic[,!(names(titanic) %in% useless)]
# str(titanic)
# ######################

#Data-Splitting
partition <- createDataPartition(df[,1], times = 1, p = 0.75,list = FALSE)
train <- titanic[partition,] # Create the training sample
test = titanic[-partition,] # Create the test sample

#############################
# Dummy-Variabeln für Kategorische (factor) Variabeln
#############################

# mit Dummy-Variabeln, können wir nun Imputation anwenden
#Dummy Variabeln für kategorische Variabeln erstellen
dummies = dummyVars(Survived ~ ., data = train, fullRank=TRUE)
#fullRank=TRUE macht aus einem Factor mit n levels n-1 dummy variabeln
train_dummies = data.frame(predict(dummies, newdata = train))
test_dummies = data.frame(predict(dummies, newdata = test))
str(train_dummies)
#Achtung: dummyVars lässt die Zielvariabel weg

#############################
# Imputation Titanic-Beispiel
#############################

sapply(titanic,function(x) sum(is.na(x)))
sapply(titanic,function(x) sum(x==""))
# Da wir bei Embarked nur zwei fehlende Werte haben und die Verteilung so aussieht
table(titanic$Embarked)
#sind die zwei mit fehlender Information mit grösseter Wahrscheinlichkeit auch "S"
titanic$Embarked[titanic$Embarked==""] <- "S"
titanic$Embarked=factor(titanic$Embarked)
table(titanic$Embarked)
#da wir Data-Splittin schon gemacht haben also noch für train und test
train$Embarked[train$Embarked==""] <- "S"
train$Embarked=factor(train$Embarked)
test$Embarked[test$Embarked==""] <- "S"
test$Embarked=factor(test$Embarked)

#Bei Age hat es sehr fehlende Information, wir anwenden also Imputation
sapply(train_dummies,function(x) sum(is.na(x)))

#Warnung ignorieren
# Imputation
pre.process <- preProcess(train_dummies, method = "bagImpute")
train_dummies <- predict(pre.process, newdata=train_dummies)
test_dummies <- predict(pre.process, newdata=test_dummies)
str(train_dummies)
train$Age=train_dummies$Age
test$Age=test_dummies$Age
#ich speichere die train- und test-Datasets noch für später
train_titanic=train
test_titanic=test

#kNN-Modell
model=train(Survived~.,data=train,method="knn")
score=predict(model,newdata=test)
confusionMatrix(score,test$Survived)
#oder mit den Dummies
model=train(y=train$Survived,x=train_dummies,method="knn")
score=predict(model,newdata=test_dummies)
confusionMatrix(score,test$Survived)

str(train)
#kNN-Modell mit Skalierung
#Skalierung
str(train)
preProcValues <- preProcess(train[,-1], method=c("center","scale"))
train=predict(preProcValues,train)
test=predict(preProcValues,test)
model=train(Survived~.,data=train,method="knn")
score=predict(model,newdata=test)
confusionMatrix(score,test$Survived)

#############################
# Feature Selection Remove Low Variance
#############################

near_zero = nearZeroVar(train_dummies, freqCut = 95/5, 
                        uniqueCut = 10, saveMetrics = TRUE)
low_variance_cols <- near_zero[(near_zero$zeroVar == TRUE) | (near_zero$nzv == TRUE), ]
near_zero
#Kommentar: bei titanic hat es keine low-Variance Variabeln
drops <- rownames(low_variance_cols)
drops
train_dummies_no_low_variance <- train_dummies[ , !(names(train_dummies) %in% drops)]

#############################
# Feature Selection mit Variable Importance mit titanic
#############################

model=train(Survived~.,data=train,method="glm")
model=train(Survived~.,data=train_titanic,method="glm")
#oder
model=train(y=train$Survived,x=train_dummies,method="glm")
#Warnung weil es zu viele Variabeln hat
var_imp = varImp(model)
plot(var_imp)
#Kommentar: man sieht, dass glm automatisch dummy-Variabeln erstellt
score=predict(model,newdata=test_dummies)
confusionMatrix(score,test$Survived)

#Wir lassen Variabeln mit Importance z.B. unter 5 weg
var_imp=varImp(model)
var_imp$importance$Imp = (var_imp$importance[,1] > 5.0)
var_imp$importance[var_imp$importance$Imp == TRUE,]
imp_names=row.names(var_imp$importance[var_imp$importance$Imp == TRUE,])
train_imp=train_dummies[,imp_names]
str(train_imp)

model_imp=train(y=train$Survived,x=train_imp,method="glm")
score_imp=predict(model_imp,newdata=test_dummies)
confusionMatrix(score_imp,test$Survived)
#Kommentar: reduziertes Modell ist gleich gut.

#############################
# Variable Importance mit swiss
#############################

library(caret)
df=swiss[,-3]
str(swiss)
partition <- sample(seq_len(nrow(df)), size = nrow(df)*0.75)
train <- df[partition, ] # Select the training rows
test <- df[-partition, ] # Select the test rows
model=train(Fertility~.,data=train,method="lm",preProc=c("center","scale","pca"))
score=predict(model,newdata=test)
postResample(score,test$Fertility)
plot(varImp(model))

str(swiss)

#############################
# Dimensional Reduction with PCA mit prcomp mit swiss
#############################

#PCA mit Base-R
df=swiss
str(swiss)
test_idx <- sort(sample(seq_len(nrow(df)), 
                        size = nrow(df)*0.75))
train <- df[test_idx, ] 
test <- df[-test_idx, ] 
pca =  prcomp(scale(train[,-1]))
plot(pca)
train=data.frame(y=train[,1],
                 pca$x)
test=data.frame(y=test[,1],
                predict(pca, test[-1]))
plot(pca)
#oder etwas schöner
library(factoextra)
fviz_eig(pca)
#Wir könnten z.B. ein Modell mit den ersten 3 PCs machen und den Rest weglassen

#############################
# Dimensional Reduction with PCA mit caret mit swiss
#############################

df=swiss
partition <- createDataPartition(df[,1], times = 1, p = 0.75,list = FALSE)
train <- df[partition,] # Create the training sample
test = df[-partition,] # Create the test sample

#hier nehme ich jetzt explizit nur die ersten 3 PC
preProcValues <- preProcess(train[,-1], method=c("center","scale","pca"),pcaComp=3)
train_pca=data.frame(Fertility=train[,1],predict(preProcValues,train[,-1]))
test_pca=data.frame(Fertility=test[,1],predict(preProcValues,test[,-1]))

#Modell ohne PCA
model.lm <- train(Fertility ~ ., data = train, method = "lm")
score=predict(model.lm,newdata=test)
postResample(test$Fertility,score)

#Modell mit PCA
model.pca <- train(Fertility ~ ., data = train_pca, method = "lm")
score=predict(model.pca,newdata=test_pca)
postResample(test$Fertility,score)

plot(varImp(model.lm))
plot(varImp(model.pca))

str(train_pca)

model.pca2 <- train(Fertility ~ ., data = train_pca[,1:3], method = "lm")
score=predict(model.pca2,newdata=test_pca)
postResample(test$Fertility,score)
plot(varImp(model.pca2))

#Kommentar: Resultat ungefähr gleich. PCA funktioniert nur gut, wenn die Zusammenhänge einigermassen linear sind.

#############################
# Cross-Validation, Bootstrapping
#############################

df=swiss
partition <- createDataPartition(df[,1], times = 1, p = 0.75,list = FALSE)
train <- df[partition,] # Create the training sample
test = df[-partition,] # Create the test sample

#Cross-Validation
train.ctrl = trainControl(
  method = 'cv',
  number = 10)
model.lm <- train(Fertility ~ ., data = train, method = "lm",
                  trControl=train.ctrl)
model.lm
score=predict(model.lm,newdata=test)
postResample(test$Fertility,score)

#Bootstrapping
train.ctrl = trainControl(
  method = 'boot',
  number = 20)
model.lm <- train(Fertility ~ ., data = train, method = "lm",
                  trControl=train.ctrl)
model.lm
score=predict(model.lm,newdata=test)
postResample(test$Fertility,score)

#Kommentar: Bei lm ist das Resultat eindeutig und braucht nicht unbedingt Cross-Validation oder Bootstrapping, bei anderen komplexeren Modellen ist das wichtig.
#Standardmässig wird immer ein Bootstrapping durchgeführt:
model.lm <- train(Fertility ~ ., data = train, method = "lm")
model.lm
# Resampling: Bootstrapped (25 reps) 

#Cross-Validation
train.ctrl = trainControl(
  method = 'cv',
  number = 10)
model <- train(Fertility ~ ., data = train, method = "blasso",
                  trControl=train.ctrl)
model
score=predict(model,newdata=test)
postResample(test$Fertility,score)

#Bootstrapping
train.ctrl = trainControl(
  method = 'boot',
  number = 20)
model <- train(Fertility ~ ., data = train, method = "blasso",
                  trControl=train.ctrl)
model
score=predict(model,newdata=test)
postResample(test$Fertility,score)

#############################
# L2 und L1 Regularization mit titanic
#############################

# Wir nehmen nochmals die ganzen Daten ohne Reduktion nach Importance
params <- getModelInfo("glmnet")
params$glmnet$parameters
tune.grid <- expand.grid(alpha=seq(0,1,by=0.1),
                         lambda=seq(0.001,0.1,by=0.001))
head(tune.grid)

pre.process <- preProcess(train_titanic, method = c("center","scale"))
train <- predict(pre.process, train_titanic)
test <- predict(pre.process, test_titanic)

model_reg = train(Survived~.,data=train,method="glmnet",tuneGrid=tune.grid)
plot(model_reg)
model_reg
score_reg=predict(model_reg,newdata=test)
confusionMatrix(score_reg,test$Survived)
#ungefaehr gleich gut wie das reduzierte Modell oben

#############################
# L2 und L1 Regularization mit breastcancer
#############################

# Dataimport
breastcancer=read.csv("breastcancer.csv")
str(breastcancer)
breastcancer=breastcancer[,-1]
breastcancer$Class=as.factor(breastcancer$Class)
# unschönes Hard-Core-Eliminieren der NA-Beobobachtungen
str(breastcancer)

df=breastcancer
partition <- createDataPartition(df[,10], times = 1, p = 0.75,list = FALSE)
train <- df[partition,] # Create the training sample
test = df[-partition,] # Create the test sample

preProcValues <- preProcess(train[,-10], method=c("center","scale","bagImpute"))
train=predict(preProcValues,train)
test=predict(preProcValues,test)

params <- getModelInfo("glmnet")
params$glmnet$parameters
tune.grid <- expand.grid(alpha=seq(0,1,by=0.1),
                         lambda=seq(0.001,0.1,by=0.001))
head(tune.grid)
model_reg = train(Class~.,data=train,method="glmnet",tuneGrid=tune.grid)
plot(model_reg)
model_reg
score_reg=predict(model_reg,newdata=test)
confusionMatrix(score_reg,test$Class)
#ungefaehr gleich gut wie das reduzierte Modell oben

#############################
# Simple Decision Trees
#############################

#Regression

#Visualisierung
library(party)
df=swiss
partition <- createDataPartition(df[,1], times = 1, p = 0.75,list = FALSE)
train <- df[partition,] # Create the training sample
test = df[-partition,] # Create the test sample
tree = ctree(Fertility ~ ., data = train)
plot(tree)
score=predict(tree,newdata=test)
postResample(score,test$Fertility)
#nicht besonders gut

#Classification
tree = ctree(Survived ~ ., data = train_titanic)
plot(tree)
score=predict(tree,newdata=test_titanic)
confusionMatrix(score,test_titanic$Survived)
#nicht besonders gut

#Kommentar: rpart ist eine andere ähnliche Entscheidungsbaum-Library
library(rpart)

#############################
# Bagging (Random Forest)
#############################

# Random Forest mit iris
df=iris
partition <- createDataPartition(df[,1], times = 1, p = 0.75, 
                                 list = FALSE)
train <- df[partition,] # Create the training sample
test <- df[-partition,] # Create the test sample
library(randomForest)
model.rf = randomForest(Species ~ ., 
                      data = train, ntree = 40)
score=predict(model.rf,newdata=test)
confusionMatrix(score,test$Species)
# oder mit caret
params <- getModelInfo("rf")
params$rf$parameters
model.rf = train(Species ~ ., data = train, method="rf")
model.rf
#mtry ist der Regularization-Parameter von RandomForest
score=predict(model.rf,newdata=test)
confusionMatrix(score,test$Species)

# Random Forest mit swiss
df=swiss
partition <- createDataPartition(df[,1], times = 1, p = 0.75, 
                                 list = FALSE)
train <- df[partition,] # Create the training sample
test <- df[-partition,] # Create the test sample
model.rf = train(Fertility ~ ., data = train, method="rf", ntree=40)
model.rf
#mtry ist der Regularization-Parameter von RandomForest
score=predict(model.rf,newdata=test)
postResample(test$Fertility,score)
#Kommentar: Funktioniert, ist aber nicht besser als mit lm, die Daten sollten wohl zuerst noch korrekt skaliert werden und vielleicht noch mit PCA transformiert
preProcValues <- preProcess(train[,-1], method=c("center","scale","pca"),pcaComp=3)
train_pca=data.frame(Fertility=train[,1],predict(preProcValues,train[,-1]))
test_pca=data.frame(Fertility=test[,1],predict(preProcValues,test[,-1]))
model.rf = train(Fertility ~ ., data = train_pca, method="rf", ntree=40)
model.rf
score=predict(model.rf,newdata=test_pca)
postResample(test$Fertility,score)
#Nun ist es doch ganz OK.


score=predict(model.rf,newdata=test)
confusionMatrix(score,test$Species)


library(randomForest)
model.rf = randomForest(Species ~ ., 
                        data = train, ntree = 40)
score=predict(model.rf,newdata=test)
confusionMatrix(score,test$Species)


#classification mit breastcancer 
breastcancer=read.csv("breastcancer.csv")

#NAs mit Imputation entfernen
str(breastcancer)
# SampleCodeNumber können wir weglassen
breastcancer=breastcancer[,-1]
table(breastcancer$Class)
#Class ist kategorisch und sollte daher in Factor umgewandelt werden
breastcancer$Class=as.factor(breastcancer$Class)
sapply(breastcancer, function(x) sum(is.na(x)))

df=breastcancer
partition <- createDataPartition(df[,1], times = 1, p = 0.75, 
                                 list = FALSE)
train <- df[partition,] # Create the training sample
test <- df[-partition,] # Create the test sample

pre.process <- preProcess(train, method = c("center","scale","bagImpute"))
train <- predict(pre.process, train)
test <- predict(pre.process, test)

# RandomForest ohne Skalierung
model.rf = train(Class ~ ., data = train, method="rf")
model.rf
#mtry ist der Regularization-Parameter von RandomForest
score=predict(model.rf,newdata=test)
confusionMatrix(score,test$Class)

# RandomForest mit Skalierung
preProcValues <- preProcess(train[,-1], method=c("center","scale","pca"),pcaComp=3)
train_pca=data.frame(Fertility=train[,1],predict(preProcValues,train[,-1]))
test_pca=data.frame(Fertility=test[,1],predict(preProcValues,test[,-1]))
model.rf = train(Class ~ ., data = train_pca, method="rf")
model.rf
score=predict(model.rf,newdata=test_pca)
confusionMatrix(score,test$Class)
# In dem Fall wurde die Vorhersage mit PCA sogar leicht schlechter

#############################
# Neural Networks
#############################

params <- getModelInfo("nnet")
params$nnet$parameters

# mit iris
df=iris
partition <- createDataPartition(df[,1], times = 1, p = 0.75, 
                                 list = FALSE)
train <- df[partition,] # Create the training sample
test <- df[-partition,] # Create the test sample

model.nnet = train(Species~.,data=train,method="nnet")
model.nnet
#mtry ist der Regularization-Parameter von RandomForest
score=predict(model.nnet,newdata=test)
confusionMatrix(score,test$Species)


# mit swiss
df=swiss
partition <- createDataPartition(df[,1], times = 1, p = 0.75, 
                                 list = FALSE)
train <- df[partition,] # Create the training sample
test <- df[-partition,] # Create the test sample
preProcValues <- preProcess(train[,-1], method=c("center","scale"))
train=data.frame(Fertility=train[,1],predict(preProcValues,train[,-1]))
test=data.frame(Fertility=test[,1],predict(preProcValues,test[,-1]))

model.nnet = train(Fertility~.,data=train,method="nnet",linout = TRUE)
model.nnet
#mtry ist der Regularization-Parameter von RandomForest
score=predict(model.nnet,newdata=test)
postResample(test$Fertility,score)


#############################
# Parallelization
#############################

library(doSNOW)
cl <- makeCluster(spec=3, type = "SOCK")
#spec: number of processes - ich nehm drei weil ich 4 cores habe

#mit breastcancer
df=breastcancer
partition <- createDataPartition(df[,1], times = 1, p = 0.75, 
                                 list = FALSE)
train <- df[partition,] # Create the training sample
test <- df[-partition,] # Create the test sample

pre.process <- preProcess(train, method = "bagImpute")
train <- predict(pre.process, train)
test <- predict(pre.process, test)

str(breastcancer)

preProcValues <- preProcess(train[,-9], method=c("center","scale"))
train=data.frame(Class=train[,9],predict(preProcValues,train[,-9]))
test=data.frame(Class=test[,9],predict(preProcValues,test[,-9]))

#Training mit Parallelization
registerDoSNOW(cl)
model.nnet = train(Class~.,data=train,method="nnet")
stopCluster(cl)

model.nnet
score=predict(model.nnet,newdata=test)
confusionMatrix(test$Class,score)

