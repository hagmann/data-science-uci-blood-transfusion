---
title: "Vorhersage der Bereitschaft für die Blutspende im Jahr 2007"
author: "Simon Hagmann"
date: "07.07.2019"
output: slidy_presentation
---

```{r echo = FALSE, message = FALSE}
source("Fallstudie.R")
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```


## Einleitung

* Explorative Datenanalyse
* Erstellen von Visualisierungen, um einen Überblick über die Daten zu erhalten.
* Aufzeigen der Korrelationen
* Aufbauen von Algorithmen
* Vergleichen der Algorithmen und den besten auswählen


## Eingesetzte Libraries

* tidyverse
* caret
* corrgram
* randomForest


## Data Exploration
```{r, echo = FALSE}
summary(blood_train)
```


## Anzahl Blutspenden

```{r, echo = FALSE}
summary(blood_train)

numDonations

monthsSinceLastDonation
```

- Die durchschnittliche Anzahl an Bluespenden ist 5.427
- Die durchschnittliche Anzahl Monate seit der letzten Blutspende ist 9.439



## Totales Volume gespendet in cc (cm^3)
```{r, echo = FALSE, warning=FALSE}
summary(blood_train$volume)

volumeDonatedTotal

volumeDonated
```

- Das Durchschnittsvolumen ist 1357cm^3



## Korrelationen
```{r, echo = FALSE, warning=FALSE}
correlation

correlation2
```


## Data Splitting
```{r, echo = TRUE}
partition_blood <- createDataPartition(blood_train[,1], times = 1, p = 0.75,list = FALSE)
train <- blood_train[partition_blood,] # Create the training sample
test = blood_train[-partition_blood,] # Create the test sample

dim(train)
dim(test)
```


## Random Forest
```{r, echo = TRUE}
model.rf = randomForest(diddonate ~ ., 
                        data = train, ntree = 40)
score=predict(model.rf,newdata=test)
confusionMatrix(score,test$diddonate)
```


## k Nearest Neighbor
```{r, echo = TRUE}
tune.grid=expand.grid(k=c(1:30))
model=train(diddonate~.,method='knn',data=train,tuneGrid=tune.grid)
model
score=predict(model,newdata=test)
confusionMatrix(score,test$diddonate)
```

## k Nearest Neighbor mit LogLoss
```{r, echo = TRUE}
tune.grid=expand.grid(k=c(1:30))
model=train(diddonate~.,method='knn',metric='LogLoss',data=train,tuneGrid=tune.grid)
model
score=predict(model,newdata=test)
confusionMatrix(score,test$diddonate)
```


## Fazit
- Der kNN Algorithmus mit LogLoss scheint im Vergleich zum random forest eine höhere Genauigkeit zu haben. Daher fällt der Entscheid auf diesen.
- kNN ohne LogLoss hat eine niedrigere Genauigkeit.

- Link zum R Code
https://github.com/hagmann/data-science-uci-blood-transfusion
